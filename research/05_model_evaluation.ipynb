{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/whysocurious/Documents/MLDSAIProjects/e2e-mlops-gcp/research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/whysocurious/Documents/MLDSAIProjects/e2e-mlops-gcp'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    top_n: int\n",
    "    ml_uri: str\n",
    "    hpo_exp: str\n",
    "    exp_name: str\n",
    "    rf_params: list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories, save_json\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            top_n=config.top_n,\n",
    "            ml_uri=config.ml_uri,\n",
    "            hpo_exp=config.hpo_exp,\n",
    "            exp_name=config.exp_name,\n",
    "            rf_params=config.rf_params,\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import pickle\n",
    "import mlflow\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlProject import logger\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    def load_pickle(self, filename):\n",
    "        with open(filename, \"rb\") as f_in:\n",
    "            return pickle.load(f_in)\n",
    "\n",
    "\n",
    "    def run_register_model(self):\n",
    "\n",
    "        mlflow.set_tracking_uri(self.config.ml_uri)\n",
    "        mlflow.set_experiment(self.config.exp_name)\n",
    "        mlflow.sklearn.autolog()\n",
    "        client = MlflowClient(tracking_uri=self.config.ml_uri)\n",
    "\n",
    "        # X_train, y_train = self.load_pickle(os.path.join(self.config.data_path, \"train.pkl\"))\n",
    "        X_val, y_val = self.load_pickle(os.path.join(self.config.data_path, \"val.pkl\"))\n",
    "        X_test, y_test = self.load_pickle(os.path.join(self.config.data_path, \"test.pkl\"))\n",
    "\n",
    "        # Retrieve the top_n model runs and log the models\n",
    "        logger.info(\"Retrieve the top_n model runs and log the models.\")\n",
    "        experiment = client.get_experiment_by_name(self.config.hpo_exp)\n",
    "        runs = client.search_runs(\n",
    "            experiment_ids=experiment.experiment_id,\n",
    "            run_view_type=ViewType.ACTIVE_ONLY,\n",
    "            max_results=self.config.top_n,\n",
    "            order_by=[\"metrics.rmse ASC\"]\n",
    "        )\n",
    "        logger.info(len(runs))\n",
    "        logger.info(\"logging top_n models wiht test metrics.\")\n",
    "        \n",
    "        for run in runs:\n",
    "            logger.info((str(run.info.run_id), str(run.data.metrics), str(run.data.params)))\n",
    "            modelPath = client.download_artifacts(run_id=run.info.run_id, path=\"model\")\n",
    "            pipeLine = self.load_pickle(os.path.join(modelPath, \"model.pkl\"))\n",
    "\n",
    "            with mlflow.start_run():\n",
    "\n",
    "                mlflow.set_tag(\"model\", \"randomforest_topN\")\n",
    "                mlflow.log_params(run.data.params)\n",
    "                \n",
    "                logger.info(\"Evaluate model on the validation and test sets\")\n",
    "                val_rmse = mean_squared_error(y_val, pipeLine.predict(X_val), squared=False)\n",
    "                mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "                test_rmse = mean_squared_error(y_test, pipeLine.predict(X_test), squared=False)\n",
    "                mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "                mlflow.sklearn.log_model(pipeLine, artifact_path=\"model\")\n",
    "\n",
    "        logger.info(\"Selecting the model with the lowest test RMSE\")\n",
    "        experiment = client.get_experiment_by_name(self.config.exp_name)\n",
    "        best_run = client.search_runs(\n",
    "            experiment_ids=experiment.experiment_id,\n",
    "            run_view_type=ViewType.ACTIVE_ONLY,\n",
    "            max_results=self.config.top_n,\n",
    "            order_by=[\"metrics.test_rmse ASC\"]\n",
    "        )[0]\n",
    "\n",
    "        # Register the best model\n",
    "        logger.info(\"Registering the best model\")\n",
    "        run_id = best_run.info.run_id\n",
    "        model_uri = f\"runs:/{run_id}/model\"\n",
    "        mlflow.register_model(model_uri=model_uri, name=\"nyc-taxi-regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 15:14:57,085: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-05 15:14:57,088: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-05 15:14:57,089: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-07-05 15:14:57,090: INFO: common: created directory at: artifacts]\n",
      "[2024-07-05 15:14:57,090: INFO: common: created directory at: artifacts/model_evaluation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/05 15:14:57 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 15:14:59,198: INFO: 141086892: Retrieve the top_n model runs and log the models.]\n",
      "[2024-07-05 15:14:59,266: INFO: 141086892: 2]\n",
      "[2024-07-05 15:14:59,267: INFO: 141086892: logging top_n models wiht test metrics.]\n",
      "[2024-07-05 15:14:59,267: INFO: 141086892: ('b62c83ca9ac647e9b34efc25183ef6de', \"{'rmse': 5.073795325986875}\", \"{'max_depth': '14', 'min_samples_leaf': '3', 'min_samples_split': '4', 'n_estimators': '15', 'random_state': '42'}\")]\n",
      "[2024-07-05 15:14:59,340: INFO: 141086892: Evaluate model on the validation and test sets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/whysocurious/.local/share/virtualenvs/e2e-mlops-gcp-OPqJYq4S/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/whysocurious/.local/share/virtualenvs/e2e-mlops-gcp-OPqJYq4S/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 15:15:20,632: INFO: 141086892: ('5c87e742ae454a35b518bd45c26b0817', \"{'rmse': 5.081163597340483}\", \"{'max_depth': '13', 'min_samples_leaf': '4', 'min_samples_split': '7', 'n_estimators': '25', 'random_state': '42'}\")]\n",
      "[2024-07-05 15:15:20,678: INFO: 141086892: Evaluate model on the validation and test sets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/whysocurious/.local/share/virtualenvs/e2e-mlops-gcp-OPqJYq4S/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/whysocurious/.local/share/virtualenvs/e2e-mlops-gcp-OPqJYq4S/lib/python3.9/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 15:15:45,827: INFO: 141086892: Selecting the model with the lowest test RMSE]\n",
      "[2024-07-05 15:15:45,853: INFO: 141086892: Registering the best model]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'nyc-taxi-regressor' already exists. Creating a new version of this model...\n",
      "2024/07/05 15:15:45 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: nyc-taxi-regressor, version 3\n",
      "Created version '3' of model 'nyc-taxi-regressor'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_evaluation_config = ModelEvaluation(config=model_evaluation_config)\n",
    "    model_evaluation_config.run_register_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e2emlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
